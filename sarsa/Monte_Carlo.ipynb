{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monte Carlo Algorithm in Reinforcement Learning\n",
    "\n",
    "Monte Carlo (MC) methods are a class of algorithms used in reinforcement learning (RL) to estimate value functions and optimize policies based on sampled episodes of experience. These methods rely on averaging sample returns to make predictions or decisions.\n",
    "\n",
    "#### Key Concepts\n",
    "\n",
    "1. **Episodes**:\n",
    "    - Monte Carlo methods require complete episodes of interaction with the environment. An episode ends when a terminal state is reached.\n",
    "\n",
    "2. **Returns**:\n",
    "    - The return $ G_t $ is the cumulative discounted reward from time step $ t $:\n",
    "      $$\n",
    "      G_t = R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + \\dots\n",
    "      $$\n",
    "    - Here, $\\gamma $ is the discount factor ($ 0 \\leq \\gamma \\leq 1 $).\n",
    "\n",
    "3. **Value Function Estimation**:\n",
    "    - Monte Carlo methods estimate the value of a state $ V(s) $ or a state-action pair $ Q(s, a) $ by averaging the returns observed after visiting that state or state-action pair.\n",
    "\n",
    "4. **Policy Improvement**:\n",
    "    - Policies are improved by making them greedy with respect to the estimated value function or action-value function.\n",
    "\n",
    "#### Types of Monte Carlo Methods\n",
    "\n",
    "1. **First-Visit MC**:\n",
    "    - Estimates the value of a state or state-action pair based on the first time it is visited in an episode.\n",
    "\n",
    "2. **Every-Visit MC**:\n",
    "    - Estimates the value by averaging the returns for every visit to a state or state-action pair in an episode.\n",
    "\n",
    "#### Monte Carlo Control\n",
    "\n",
    "Monte Carlo control combines policy evaluation and policy improvement to find the optimal policy. The steps are:\n",
    "\n",
    "1. **Policy Evaluation**:\n",
    "    - Use sampled episodes to estimate $ Q(s, a) $ for the current policy.\n",
    "\n",
    "2. **Policy Improvement**:\n",
    "    - Update the policy to be greedy with respect to $ Q(s, a) $:\n",
    "      $$\n",
    "      \\pi(s) = \\arg\\max_a Q(s, a)\n",
    "      $$\n",
    "\n",
    "3. **Exploration**:\n",
    "    - To ensure all state-action pairs are explored, an exploration strategy like $ \\epsilon $-greedy is used.\n",
    "\n",
    "#### Advantages\n",
    "\n",
    "- Simple to implement.\n",
    "- Does not require knowledge of the environment's dynamics (model-free).\n",
    "- Works well with episodic tasks.\n",
    "\n",
    "#### Limitations\n",
    "\n",
    "- Requires complete episodes, which may not be feasible in some environments.\n",
    "- High variance in estimates due to reliance on sampled episodes.\n",
    "- Inefficient for large state or action spaces.\n",
    "\n",
    "Monte Carlo methods are foundational in RL and are often used as a baseline for understanding more advanced algorithms like Temporal Difference (TD) learning and Deep Reinforcement Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def create_colored_grid(m, n, colors=None):\n",
    "    # Create an MxN grid of 0s\n",
    "    grid = np.zeros((m, n))\n",
    "\n",
    "    # If specific colors are passed, assign them to the grid\n",
    "    if colors.any():\n",
    "        grid = np.array(colors).reshape((m, n))\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Display the grid as a color matrix\n",
    "    cax = ax.matshow(grid, cmap='viridis', interpolation='nearest')\n",
    "\n",
    "    # Optionally, add colorbar\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set gridlines for better visibility\n",
    "    ax.set_xticks(np.arange(0, n, 1))\n",
    "    ax.set_yticks(np.arange(0, m, 1))\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticks(np.arange(-.5, n, 1), minor=True)\n",
    "    ax.set_yticks(np.arange(-.5, m, 1), minor=True)\n",
    "    ax.grid(which='minor', color='black', linestyle='-', linewidth=2)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "m, n = 5, 5  # Dimensions of the grid\n",
    "colors = np.random.rand(m * n)  # Random colors for each box\n",
    "create_colored_grid(m, n, colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21323383, 0.53597841, 0.53590501, 0.8624484 , 0.99920289],\n",
       "       [0.25298471, 0.9878607 , 0.92669171, 0.38389244, 0.11708954],\n",
       "       [0.19396562, 0.28271263, 0.25894005, 0.33724682, 0.44967427],\n",
       "       [0.9033413 , 0.85761107, 0.34864629, 0.95189567, 0.55629833],\n",
       "       [0.08133939, 0.75629644, 0.95157913, 0.91970074, 0.99198711]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colors = np.random.rand(m * n)  # Random colors for each box\n",
    "colors.reshape((m, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "def create_colored_grid(m, n, color_map):\n",
    "    # Create an MxN grid with random integers from 0 to 2 (representing 3 colors)\n",
    "    grid = np.random.randint(0, 3, size=(m, n))\n",
    "\n",
    "    grid[0, 0] = 0\n",
    "    grid[0, 1] = 0\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Use a custom colormap with green, blue, and orange\n",
    "    cmap = mcolors.ListedColormap(color_map)\n",
    "    bounds = [0, 1, 2, 3]  # Boundaries for each color (0 -> green, 1 -> blue, 2 -> orange)\n",
    "    norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "    # Display the grid as a color matrix\n",
    "    cax = ax.matshow(grid, cmap=cmap, norm=norm, interpolation='nearest')\n",
    "\n",
    "    # Optionally, add a colorbar to show the color mapping\n",
    "    cbar = fig.colorbar(cax, ticks=[0, 1, 2])\n",
    "    cbar.ax.set_yticklabels(['Green', 'Blue', 'Visited'])\n",
    "\n",
    "    # Set gridlines for better visibility\n",
    "    ax.set_xticks(np.arange(0, n, 1))\n",
    "    ax.set_yticks(np.arange(0, m, 1))\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticks(np.arange(-.5, n, 1), minor=True)\n",
    "    ax.set_yticks(np.arange(-.5, m, 1), minor=True)\n",
    "    ax.grid(which='minor', color='black', linestyle='-', linewidth=2)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Define the colors you want to use (green, blue, orange)\n",
    "color_map = ['green', 'blue', 'orange']\n",
    "\n",
    "# Example usage\n",
    "m, n = 5, 5  # Dimensions of the grid\n",
    "create_colored_grid(m, n, color_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#cliff walking env\n",
    "class environment:\n",
    "    def __init__(self, nRow, nCol, nA):\n",
    "\n",
    "        self.nRow = nRow\n",
    "        self.nCol = nCol\n",
    "\n",
    "        \n",
    "        self.nS = nRow * nCol  # Number of states\n",
    "        self.nA = nA  # Number of actions\n",
    "        self.actions =[0, 1, 2, 3] # Actions: 0=left, 1=down, 2=right, 3=up\n",
    "        self.V = np.zeros(self.nS)  # Value function\n",
    "        self.Q = np.zeros((self.nS, self.nA)) # Q-value function\n",
    "        self.state = 0  # Initial state\n",
    "\n",
    "        self.grid  = np.zeros((nRow, nCol))  # Initialize the grid\n",
    "        self.grid[0, 0] = 3  # Start state\n",
    "        self.grid[0, nCol - 1] = 2  # Goal state\n",
    "        # Define the grid size\n",
    "        self.grid[0, 1:(self.nCol - 1)] = 1\n",
    "        # lets make bottom row except for first and last column as cliff\n",
    "\n",
    "        self.render()\n",
    "        \n",
    "    def state_to_grid(self, state):\n",
    "        # Convert state index to grid coordinates\n",
    "        row = state // self.nCol\n",
    "        col = state % self.nCol\n",
    "        return row, col\n",
    "        \n",
    "\n",
    "    def reset(self):\n",
    "        self.state = 0  # Reset to initial state\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "\n",
    "        # if state is top edge or left edge or right edge, up , left, right action should not be taken\n",
    "\n",
    "        #top edge\n",
    "        if ((self.nRow - 1) * self.nCol) <= self.state < self.nRow * self.nCol:\n",
    "            if action == 3:\n",
    "                return self.state, -100, True\n",
    "        #left edge\n",
    "        if self.state % self.nCol == 0:\n",
    "            if action == 0:\n",
    "                return self.state, -100, True\n",
    "        #right edge\n",
    "        if (self.state + 1) % self.nCol == 0:\n",
    "            if action == 2:\n",
    "                return self.state, -100, True\n",
    "        #bottom edge\n",
    "        if self.state < self.nCol:\n",
    "            if action == 1:\n",
    "                return self.state, -100, True\n",
    "            \n",
    "\n",
    "\n",
    "        # Define the transition and reward logic here\n",
    "        if action == 0:\n",
    "            self.state -= 1\n",
    "        elif action == 1:\n",
    "            self.state += self.nCol\n",
    "        elif action == 2:\n",
    "            self.state += 1\n",
    "        elif action == 3:\n",
    "            self.state -= self.nCol\n",
    "\n",
    "        # if the state is in the cliff, return -100\n",
    "        if self.state in range(1, self.nCol - 1):\n",
    "            return self.state, -100, True\n",
    "        \n",
    "        if self.state == self.nCol - 1:\n",
    "            # Reached the goal state\n",
    "            return self.state, 100, True\n",
    "\n",
    "        return self.state, -1, False  # Return next state, reward, and done flag\n",
    "    \n",
    "\n",
    "    def choose_action(env):\n",
    "        # Define the action space\n",
    "        # Randomly choose an action\n",
    "        chosen_action = np.random.choice(4)\n",
    "        \n",
    "        return chosen_action\n",
    "\n",
    "\n",
    "    def epsilon_greedy(env, state, epsilon=0.1):\n",
    "        \"\"\"\n",
    "        Epsilon-greedy policy for action selection.\n",
    "\n",
    "        Args:\n",
    "            env: The environment object.\n",
    "            state: The current state.\n",
    "            Q: The Q-table (a dictionary or 2D array).\n",
    "            epsilon: The probability of choosing a random action.\n",
    "\n",
    "        Returns:\n",
    "            The selected action.\n",
    "        \"\"\"\n",
    "        if np.random.rand() < epsilon:\n",
    "            # Choose a random action\n",
    "            action = np.random.choice(env.actions)\n",
    "        else:\n",
    "            # Choose the action with the highest Q-value for the current state\n",
    "            action = np.argmax(env.Q[state])\n",
    "\n",
    "        return action\n",
    "\n",
    "    def render(self):\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "        color_map = ['green','red', 'blue', 'orange']\n",
    "\n",
    "    # Use a custom colormap with green, blue, and orange\n",
    "        cmap = mcolors.ListedColormap(color_map)\n",
    "        bounds = [0, 1, 2, 3, 4]  # Boundaries for each color (0 -> green, 1 -> blue, 2 -> orange)\n",
    "        norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "        # Display the grid as a color matrix\n",
    "        cax = ax.matshow(self.grid, cmap=cmap, norm=norm, interpolation='nearest')\n",
    "\n",
    "        # Optionally, add a colorbar to show the color mapping\n",
    "        cbar = fig.colorbar(cax, ticks=[0, 1, 2])\n",
    "        cbar.ax.set_yticklabels(['Blue','Green', 'Y', 'Visited'])\n",
    "\n",
    "        # Set gridlines for better visibility\n",
    "        ax.set_xticks(np.arange(0, n, 1))\n",
    "        ax.set_yticks(np.arange(0, m, 1))\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_xticks(np.arange(-.5, n, 1), minor=True)\n",
    "        ax.set_yticks(np.arange(-.5, m, 1), minor=True)\n",
    "        ax.grid(which='minor', color='black', linestyle='-', linewidth=2)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    def get_policy(env):\n",
    "        policy = np.zeros(env.nS, dtype=int)  # Initialize policy array\n",
    "        for state in range(env.nS):\n",
    "            action = np.argmax(env.Q[state])\n",
    "            policy[state] = action\n",
    "\n",
    "        return policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#monte carlo with value funcation\n",
    "def monte_carlo(env, num_episodes=1000, gamma=0.9):\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        # Generate an episode\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        rewards = []\n",
    "        states_visited = []\n",
    "        states_visited.append(state)\n",
    "\n",
    "        while not done:\n",
    "            action = env.epsilon_greedy(state)\n",
    "            next_state, reward, done = env.step(action)\n",
    "\n",
    "            env.Q[state, action] += reward\n",
    "\n",
    "            print(next_state, reward, done)\n",
    "            rewards.append(reward)\n",
    "            states_visited.append(next_state)\n",
    "        \n",
    "\n",
    "        # Calculate the cumulative reward for each state\n",
    "        G = 0\n",
    "        cumulative_rewards = []\n",
    "        for t in reversed(range(len(rewards))):\n",
    "            G = rewards[t] + gamma * G\n",
    "            cumulative_rewards.insert(0, G)\n",
    "            state = states_visited[t]\n",
    "            # Update the value function\n",
    "            env.V[state] += (G - env.V[state]) / (episode + 1)\n",
    "\n",
    "    return env.policy, env.V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of FixedLocator locations (5), usually from a call to set_ticks, does not match the number of labels (4).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 184\u001b[0m\n\u001b[1;32m    180\u001b[0m             env\u001b[38;5;241m.\u001b[39mV[state] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (G \u001b[38;5;241m-\u001b[39m env\u001b[38;5;241m.\u001b[39mV[state]) \u001b[38;5;241m/\u001b[39m (episode \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env\u001b[38;5;241m.\u001b[39mget_policy(), env\u001b[38;5;241m.\u001b[39mV\n\u001b[0;32m--> 184\u001b[0m Cliff_walker \u001b[38;5;241m=\u001b[39m \u001b[43menvironment\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m policy, V \u001b[38;5;241m=\u001b[39m monte_carlo(Cliff_walker, num_episodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m)\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal Policy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, policy)\n",
      "Cell \u001b[0;32mIn[6], line 26\u001b[0m, in \u001b[0;36menvironment.__init__\u001b[0;34m(self, nRow, nCol, nA)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrid[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m:(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnCol \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# lets make bottom row except for first and last column as cliff\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 134\u001b[0m, in \u001b[0;36menvironment.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# Optionally, add a colorbar to show the color mapping\u001b[39;00m\n\u001b[1;32m    133\u001b[0m cbar \u001b[38;5;241m=\u001b[39m fig\u001b[38;5;241m.\u001b[39mcolorbar(cax, ticks\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m])\n\u001b[0;32m--> 134\u001b[0m \u001b[43mcbar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_yticklabels\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgreen\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mred\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mblue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43morange\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Set gridlines for better visibility\u001b[39;00m\n\u001b[1;32m    137\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_xticks(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnRow, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/projects/volunteering/Paddle-RLBooks/venv/lib/python3.10/site-packages/matplotlib/axes/_base.py:74\u001b[0m, in \u001b[0;36m_axis_method_wrapper.__set_name__.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/volunteering/Paddle-RLBooks/venv/lib/python3.10/site-packages/matplotlib/axis.py:2106\u001b[0m, in \u001b[0;36mAxis.set_ticklabels\u001b[0;34m(self, labels, minor, fontdict, **kwargs)\u001b[0m\n\u001b[1;32m   2102\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(locator, mticker\u001b[38;5;241m.\u001b[39mFixedLocator):\n\u001b[1;32m   2103\u001b[0m     \u001b[38;5;66;03m# Passing [] as a list of labels is often used as a way to\u001b[39;00m\n\u001b[1;32m   2104\u001b[0m     \u001b[38;5;66;03m# remove all tick labels, so only error for > 0 labels\u001b[39;00m\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(locator\u001b[38;5;241m.\u001b[39mlocs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(labels) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(labels) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2106\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2107\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of FixedLocator locations\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2108\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(locator\u001b[38;5;241m.\u001b[39mlocs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m), usually from a call to\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2109\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m set_ticks, does not match\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2110\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m the number of labels (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(labels)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2111\u001b[0m     tickd \u001b[38;5;241m=\u001b[39m {loc: lab \u001b[38;5;28;01mfor\u001b[39;00m loc, lab \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(locator\u001b[38;5;241m.\u001b[39mlocs, labels)}\n\u001b[1;32m   2112\u001b[0m     func \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_with_dict, tickd)\n",
      "\u001b[0;31mValueError\u001b[0m: The number of FixedLocator locations (5), usually from a call to set_ticks, does not match the number of labels (4)."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#cliff walking env\n",
    "class environment:\n",
    "    def __init__(self, nRow, nCol, nA):\n",
    "\n",
    "        self.nRow = nRow\n",
    "        self.nCol = nCol\n",
    "\n",
    "        \n",
    "        self.nS = nRow * nCol  # Number of states\n",
    "        self.nA = nA  # Number of actions\n",
    "        self.actions =[0, 1, 2, 3] # Actions: 0=left, 1=down, 2=right, 3=up\n",
    "        self.V = np.zeros(self.nS)  # Value function\n",
    "        self.Q = np.zeros((self.nS, self.nA)) # Q-value function\n",
    "        self.state = 0  # Initial state\n",
    "\n",
    "        self.grid  = np.zeros((nRow, nCol))  # Initialize the grid\n",
    "        # Define the grid size\n",
    "        self.grid[0, 1:(self.nCol - 1)] = 1\n",
    "        # lets make bottom row except for first and last column as cliff\n",
    "\n",
    "        self.render()\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "    def reset(self):\n",
    "        self.state = 0  # Reset to initial state\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "\n",
    "        # if state is top edge or left edge or right edge, up , left, right action should not be taken\n",
    "\n",
    "        #top edge\n",
    "        if ((self.nRow - 1) * self.nCol) <= self.state < self.nRow * self.nCol:\n",
    "            if action == 3:\n",
    "                return self.state, -100, True\n",
    "        #left edge\n",
    "        if self.state % self.nCol == 0:\n",
    "            if action == 0:\n",
    "                return self.state, -100, True\n",
    "        #right edge\n",
    "        if (self.state + 1) % self.nCol == 0:\n",
    "            if action == 2:\n",
    "                return self.state, -100, True\n",
    "        #bottom edge\n",
    "        if self.state < self.nCol:\n",
    "            if action == 1:\n",
    "                return self.state, -100, True\n",
    "            \n",
    "\n",
    "\n",
    "        # Define the transition and reward logic here\n",
    "        if action == 0:\n",
    "            self.state -= 1\n",
    "        elif action == 1:\n",
    "            self.state += self.nCol\n",
    "        elif action == 2:\n",
    "            self.state += 1\n",
    "        elif action == 3:\n",
    "            self.state -= self.nCol\n",
    "\n",
    "        # if the state is in the cliff, return -100\n",
    "        if self.state in range(1, self.nCol - 1):\n",
    "            return self.state, -100, True\n",
    "        \n",
    "        if self.state == self.nCol - 1:\n",
    "            # Reached the goal state\n",
    "            return self.state, 100, True\n",
    "\n",
    "        return self.state, -1, False  # Return next state, reward, and done flag\n",
    "    \n",
    "\n",
    "    def choose_action(env):\n",
    "        # Define the action space\n",
    "        # Randomly choose an action\n",
    "        chosen_action = np.random.choice(4)\n",
    "        \n",
    "        return chosen_action\n",
    "\n",
    "\n",
    "    def epsilon_greedy(env, state, epsilon=0.1):\n",
    "        \"\"\"\n",
    "        Epsilon-greedy policy for action selection.\n",
    "\n",
    "        Args:\n",
    "            env: The environment object.\n",
    "            state: The current state.\n",
    "            Q: The Q-table (a dictionary or 2D array).\n",
    "            epsilon: The probability of choosing a random action.\n",
    "\n",
    "        Returns:\n",
    "            The selected action.\n",
    "        \"\"\"\n",
    "        if np.random.rand() < epsilon:\n",
    "            # Choose a random action\n",
    "            action = np.random.choice(env.actions)\n",
    "        else:\n",
    "            # Choose the action with the highest Q-value for the current state\n",
    "            action = np.argmax(env.Q[state])\n",
    "\n",
    "        return action\n",
    "\n",
    "\n",
    "    def get_policy(env):\n",
    "        policy = np.zeros(env.nS, dtype=int)  # Initialize policy array\n",
    "        for state in range(env.nS):\n",
    "            action = np.argmax(env.Q[state])\n",
    "            policy[state] = action\n",
    "\n",
    "        return policy\n",
    "    \n",
    "    def render(self):\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "        color_map = ['green','red', 'blue', 'orange']\n",
    "\n",
    "        # Use a custom colormap with green, blue, and orange\n",
    "        cmap = mcolors.ListedColormap(color_map)\n",
    "        bounds = [0, 1, 2, 3, 4]  # Boundaries for each color (0 -> green, 1 -> red, 2 -> blue, 3 -> orange)\n",
    "        norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "        # Display the grid as a color matrix\n",
    "        cax = ax.matshow(self.grid, cmap=cmap, norm=norm, interpolation='nearest')\n",
    "\n",
    "        # Optionally, add a colorbar to show the color mapping\n",
    "        cbar = fig.colorbar(cax, ticks=[0, 1, 2, 3, 4])\n",
    "        cbar.ax.set_yticklabels(['green','red', 'blue', 'orange'])\n",
    "\n",
    "        # Set gridlines for better visibility\n",
    "        ax.set_xticks(np.arange(0, self.nRow, 1))\n",
    "        ax.set_yticks(np.arange(0, self.nCol, 1))\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_xticks(np.arange(-.5, self.nRow, 1), minor=True)\n",
    "        ax.set_yticks(np.arange(-.5, self.nCol, 1), minor=True)\n",
    "        ax.grid(which='minor', color='black', linestyle='-', linewidth=2)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#monte carlo with value funcation\n",
    "def monte_carlo(env, num_episodes=1000, gamma=0.9):\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        # Generate an episode\n",
    "        env.reset()\n",
    "        done = False\n",
    "        rewards = []\n",
    "        states_visited = []\n",
    "        states_visited.append(env.state)\n",
    "\n",
    "        while not done:\n",
    "            action = env.epsilon_greedy(env.state)\n",
    "            next_state, reward, done = env.step(action)\n",
    "\n",
    "            env.Q[env.state, action] += reward\n",
    "\n",
    "            print(next_state, reward, done, action)\n",
    "            rewards.append(reward)\n",
    "            states_visited.append(next_state)\n",
    "        \n",
    "\n",
    "        # Calculate the cumulative reward for each state\n",
    "        G = 0\n",
    "        cumulative_rewards = []\n",
    "        for t in reversed(range(len(rewards))):\n",
    "            G = rewards[t] + gamma * G\n",
    "            cumulative_rewards.insert(0, G)\n",
    "            state = states_visited[t]\n",
    "            # Update the value function\n",
    "            env.V[state] += (G - env.V[state]) / (episode + 1)\n",
    "\n",
    "    return env.get_policy(), env.V\n",
    "\n",
    "Cliff_walker = environment(4, 12, 4)\n",
    "policy, V = monte_carlo(Cliff_walker, num_episodes=1000, gamma=0.9)\n",
    "print(\"Final Policy:\", policy)\n",
    "print(\"Final Value Function:\", V.reshape(4, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
